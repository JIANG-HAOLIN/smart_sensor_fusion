# config_dummy_aloha.yaml


defaults:
- datasets: dummy
- models: aloha/vae_vanilla
- optimizers: adam_cosine
- pl_modules: aloha/aloha
- trainers: dummy
- _self_


# General settings
task_name: "dummy_aloha"
variable_name: trainers.launch_trainer.repeat_trial
output_name: debug
seed: 42
results_dir: '/home/jin4rng/Documents/code/smart_sensor_fusion/results'
data_folder_path: '/fs/scratch/rb_bd_dlp_rng-dl01_cr_ROB_employees/students/jin4rng/data/robot_demo'

hydra:
  sweeper:
    params:
      trainers.launch_trainer.repeat_trial: 1
      trainers.launch_trainer.max_epochs: 300
      trainers.launch_trainer.monitor:  "val_vae_loss"
      datasets.dataloader.data_folder: ${data_folder_path}
      datasets.dataloader.args.num_stack: 10
      datasets.dataloader.args.len_lb: 10
      datasets.dataloader.batch_size: 32
      pl_modules.pl_module.num_stack: ${datasets.dataloader.args.num_stack}
      pl_modules.pl_module.action: "delta"
      models.model.replace_args.state_dim: 6
      optimizers.optimizer.lr: 0.00001
      optimizers.optimizer.weight_decay: 0.0001
      datasets.dataloader.args.resized_height_v: 480
      datasets.dataloader.args.resized_width_v: 640
      optimizers.scheduler.num_warmup_steps: 2320
      optimizers.scheduler.num_training_steps: 23200

  sweep:  # didn't use ${hydra.runtime.choices.pl_modules} because "/" \\ if add timestamp: _${now:%m-%d-%H:%M:%S}
    dir: ${results_dir}/${task_name}/${datasets.name}/${output_name}/${pl_modules.name}_${models.name}_${optimizers.name}/
    # only controls where config.yaml is saved
    subdir: ./
  run: # control where multirun.yaml is saved
    dir: ${hydra.sweep.sub}/.hydra







