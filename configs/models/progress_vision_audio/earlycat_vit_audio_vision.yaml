name: 'earlycat_vit_audio_vision'

model:
  _target_: src.models.progress_prediction.VisionAudioFusion

  preprocess_audio_args:
    _target_: src.models.utils.mel_spec.MelSpec
    length: 40000
    sr: 16000
    n_mels: 64
    norm_audio: false
    hop_ratio: 0.05
  tokenization_audio:
    _target_: src.models.utils.tokenization.VanillaTokenization
    channel_size: 1
    patch_size: [64, 3]
    input_size: [64, 51]
    model_dim: 256
  pe_audio:
    _target_: src.models.utils.positional_encoding.StandardPositionalEncoding
    d_model: 256
  encoder_audio_args:
    _target_: src.models.encoders.identity.get_identity_encoder

  preprocess_vision_args:
    _target_: src.models.encoders.identity.get_identity_encoder
  tokenization_vision:
    _target_: src.models.utils.tokenization.VanillaTokenization
    channel_size: 3
    patch_size: [ 16, 16 ]
    input_size: [ 67, 90 ]
    model_dim: 256
  pe_vision:
    _target_: src.models.utils.positional_encoding.StandardPositionalEncoding
    d_model: 256
  encoder_vision_args:
    _target_: src.models.encoders.identity.get_identity_encoder

  transformer_classifier_args:
    _target_: src.models.trafo_classifier_vit.TransformerClassifierVitNoPatch
    model_dim: 256
    num_classes: 10
    num_heads: 8
    dropout: 0.0
    input_dropout: 0.0
    add_positional_encoding: True
    num_layers: 4



inference:
  ckpt_path: ' '

