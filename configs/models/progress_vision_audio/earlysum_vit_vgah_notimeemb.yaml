name: 'earlysum_vit_vgah_notimeemb'

model:
  _target_: src.models.progress_prediction.VisionAudioFusion_EarlySum
  model_dim: 256
  preprocess_audio_args:
    _target_: src.models.utils.mel_spec.MelSpec
    length: 40000
    sr: 16000
    n_mels: 64
    norm_audio: false
    hop_ratio: 0.05
  tokenization_audio:
    _target_: src.models.utils.tokenization.Vanilla2dTokenization
    channel_size: 1
    patch_size: [64, 10]
    input_size: [64, 51]
    model_dim: ${models.model.model_dim}
  pe_audio:
    _target_: src.models.encoders.identity.get_identity_encoder
  encoder_audio_args:
    _target_: src.models.encoders.identity.get_identity_encoder


  preprocess_vision_args:
    _target_: src.models.encoders.res_net_18.make_vision_encoder
    out_dim: ${models.model.model_dim}
    out_layer: "layer4.1.relu_1"
  tokenization_vision:
    _target_: src.models.encoders.identity.get_identity_encoder
  pe_vision:
    _target_: src.models.encoders.identity.get_identity_encoder
  encoder_vision_args:
    _target_: src.models.encoders.identity.get_identity_encoder


  pos_emb_args:
    _target_: src.models.utils.positional_encoding.StandardPositionalEncoding
    d_model: 512


  transformer_classifier_args:
    _target_: src.models.trafo_classifier_vit.TransformerClassifierVitNoPatch
    model_dim: 512
    num_classes: 10
    num_heads: 8
    dropout: 0.0
    input_dropout: 0.0
    num_layers: 4
    add_positional_encoding: False



inference:
  ckpt_path: ' '

