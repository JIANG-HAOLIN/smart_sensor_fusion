name: 'earlycat_vit_vgah_notimeemb'

model:
  _target_: src.models.seehear_imitation.VisionAudioFusion_Supervised
  model_dim: 512
  preprocess_audio_args:
    _target_: src.models.utils.mel_spec.MelSpec
    length: 40000
    sr: 16000
    n_mels: 64
    norm_audio: false
    hop_ratio: 0.05
  tokenization_audio:
    _target_: src.models.utils.tokenization.Vanilla2dTokenization
    channel_size: 1
    patch_size: [64, 3]
    input_size: [64, 51]
    model_dim: ${models.model.model_dim}
  pe_audio:
    _target_: src.models.utils.positional_encoding.StandardPositionalEncoding
    d_model: ${models.model.model_dim}
  encoder_audio_args:
    _target_: src.models.transformer_implementations.TransformerEncoder
    token_dim: ${models.model.model_dim}
    num_blocks: 4
    num_heads: 8
    dropout: 0.0
    batch_first: True
    norm_first: True

  preprocess_vision_args:
    _target_: src.models.encoders.identity.get_identity_encoder
  tokenization_vision:
    _target_: src.models.utils.tokenization.Vanilla2dTokenization
    channel_size: 3
    patch_size: [ 16, 16 ]
    input_size: [ 67, 90 ]
    model_dim: ${models.model.model_dim}
  pe_vision:
    _target_: src.models.utils.embeddings.VitPatchEmbedding
    emb_dim: ${models.model.model_dim}
    num_patches: 100
  encoder_vision_args:
    _target_: src.models.transformer_implementations.TransformerEncoder
    token_dim: ${models.model.model_dim}
    num_blocks: 4
    num_heads: 8
    dropout: 0.0
    batch_first: True
    norm_first: True

  last_pos_emb_args:
    _target_: src.models.utils.embeddings.ModalTypeEmbedding
    num_type: 3
    emb_dim: ${models.model.model_dim}

  transformer_args:
    _target_: src.models.transformer_implementations.TransformerEncoder
    token_dim: ${models.model.model_dim}
    num_blocks: 4
    num_heads: 8
    batch_first: True
    norm_first: True



inference:
  ckpt_path: ' '

