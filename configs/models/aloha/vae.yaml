name: 'vae'

model:
  _target_: src.models.aloha.build_detrvae
  action_dim: 6
  style_encoder:
    lr: 1e-05
    lr_backbone: 1e-05
    batch_size: 8
    weight_decay: 0.0001
    epochs: 300
    lr_drop: 200
    clip_max_norm: 0.1

    dilation: False
    position_embedding: 'sine'

    enc_layers: 4
    dec_layers: 7
    dim_feedforward: 3200
    hidden_dim: 512
    dropout: 0.1
    nheads: 8

    pre_norm: False
    masks: False
    eval: False
    onscreen_render: False
    ckpt_dir: 'ckp_dir'
    policy_class: 'ACT'
    task_name: 'sim_transfer_cube_scripted'
    num_epochs: 2000
    kl_weight: 10
    chunk_size: 100
    temporal_agg: False

  action_decoder:
    lr: 1e-05
    lr_backbone: 1e-05
    batch_size: 8
    weight_decay: 0.0001
    epochs: 300
    lr_drop: 200
    clip_max_norm: 0.1

    dilation: False
    position_embedding: 'sine'

    enc_layers: 4
    dec_layers: 7
    dim_feedforward: 3200
    hidden_dim: 512
    dropout: 0.1
    nheads: 8
    num_queries: 20
    pre_norm: False
    masks: False
    eval: False
    onscreen_render: False
    ckpt_dir: 'ckp_dir'
    policy_class: 'ACT'
    task_name: 'sim_transfer_cube_scripted'
    num_epochs: 2000
    kl_weight: 10
    chunk_size: 100
    temporal_agg: False


  obs_encoder:
    #---------------------------------------------------------------------------------------------------------#
    _target_: src.models.ssl_nce_framework.SslNceFramework_EarlySum_VATT_addtional
    mod_names: ["vision","audio","tactile"]
    main_mod: "vision"
    model_dim: 512
    num_stack: 10  # num_frame / short_window_len

    nce_args:
      norm: batch
      main_mod: ${models.model.obs_encoder.main_mod}
      temp: 1.0
      nce_proj_head:
        _target_: src.models.utils.helpers.ImageBindNceHeader
        model_dim: ${models.model.obs_encoder.model_dim}
        dropout: 0.

    mask_args:
      mask_type: raw
      masked_mod: ["vision", "audio", "tactile"]
      mask_prob:
        latent: 0.5
        vision: 0.5
        audio: 0.08
        tactile: 0.5
      mask_length:
        latent: 1
        vision: 1
        audio: 10
        tactile: 1

    mask_fusion_nce:
      temp: 1.0
      proj_head:
        _target_: src.models.utils.helpers.ImageBindNceHeader
        model_dim: ${models.model.obs_encoder.model_dim}
        dropout: 0.
    mask_cross_time_trf_nce:
      temp: 1.0
      proj_head:
        _target_: src.models.utils.helpers.ImageBindNceHeader
        model_dim: ${models.model.obs_encoder.model_dim}
        dropout: 0.
    mask_latent_prediction:
      momentum: False
      loss: mse
      predictor:
        _target_: src.models.utils.header.MLPHead
        in_dim: ${models.model.obs_encoder.model_dim}
        out_dim: ${models.model.obs_encoder.model_dim}
        dropout: 0.
        norm: layer

    fom_args:
      reorder_prob: 0.2
      predictor:
        _target_: src.models.utils.header.MLPHead
        in_dim: ${models.model.obs_encoder.model_dim}
        out_dim: ${models.model.obs_encoder.num_stack}
        dropout: 0.
        norm: layer
    #---------------------------------------------------------------------------------------------------------#
    audio_args:
      preprocess_audio_args:
        _target_: src.models.utils.mel_spec.MelSpec
        windows_size: 0.05
        length: 80000
        sr: 16000
        n_mels: 64
        norm_audio: false
        hop: 0.05
      tokenization_audio:
        _target_: src.models.utils.tokenization.Vanilla2dTokenization
        channel_size: 1
        input_size:
          - ${models.model.obs_encoder.audio_args.preprocess_audio_args.n_mels}
          - 101
        patch_size:
          - ${models.model.obs_encoder.audio_args.preprocess_audio_args.n_mels}
          - 10
        model_dim: ${models.model.obs_encoder.model_dim}
      pe_audio:
        _target_: src.models.encoders.identity.get_identity_encoder
      encoder_audio_args:
        _target_: src.models.encoders.identity.get_identity_encoder

    vision_args:
      short_window_len: 1
      preprocess_vision_args:
        _target_: src.models.encoders.identity.get_identity_encoder
      tokenization_vision:
        _target_: src.models.vit_implementations.VitVATT3D
        channel_size: 3
        model_dim: ${models.model.obs_encoder.model_dim}
        num_heads: 8
        num_layers: 4
        patch_size:
          - 1
          - 8
          - 8
        input_size: # first dim = short_window_len
          - 1
          - 67
          - 90
        num_emb: 100
      pe_vision:
        _target_: src.models.encoders.identity.get_identity_encoder
      encoder_vision_args:
        _target_: src.models.encoders.identity.get_identity_encoder

    tactile_args:
      short_window_len: 1
      preprocess_tactile_args:
        _target_: src.models.encoders.identity.get_identity_encoder
      tokenization_tactile:
        _target_: src.models.vit_implementations.VitVATT3D
        channel_size: 3
        model_dim: ${models.model.obs_encoder.model_dim}
        num_heads: 8
        num_layers: 4
        patch_size:
          - 1
          - 6
          - 6
        input_size: # first dim = short_window_len
          - 1
          - 54
          - 72
        num_emb: 109  # 1 more aggregation token
      pe_tactile:
        _target_: src.models.encoders.identity.get_identity_encoder
      encoder_tactile_args:
        _target_: src.models.encoders.identity.get_identity_encoder
    #---------------------------------------------------------------------------------------------------------#

    fusion_args:
      _target_: src.models.utils.fusion.EarlySum
      mod_names: ${models.model.obs_encoder.mod_names}
      dim: ${models.model.obs_encoder.model_dim}


    pos_emb_args:
      _target_: src.models.utils.positional_encoding.StandardPositionalEncoding
      d_model: ${models.model.obs_encoder.model_dim}


    cross_time_trf_args:
      _target_: src.models.transformer_implementations.TransformerEncoderVanilla
      token_dim: ${models.model.obs_encoder.model_dim}
      num_heads: 8
      num_blocks: 4



inference:
  ckpt_path: ' '

