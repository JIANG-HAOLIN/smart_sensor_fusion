name: 'ssnce_earlysum_vatt_additional'

model:
  #---------------------------------------------------------------------------------------------------------#
  _target_: src.models.ssl_nce_framework.SslNceFramework_EarlySum_VATT_addtional
  mod_names: ["vision"]
  main_mod: "vision"
  model_dim: 768
  num_stack: 10  # num_frame / short_window_len

  nce_args:
    norm: batch
    main_mod: ${models.model.main_mod}
    temp: 1.0
    nce_proj_head:
      _target_: src.models.utils.helpers.ImageBindNceHeader
      model_dim: ${models.model.model_dim}
      dropout: 0.

  mask_args:
    mask_type: raw
    masked_mod: ["vision"]
    mask_prob:
      latent: 0.5
      vision: 0.5
      audio: 0.08
      tactile: 0.5
    mask_length:
      latent: 1
      vision: 1
      audio: 10
      tactile: 1

  mask_fusion_nce:
    temp: 1.0
    proj_head:
      _target_: src.models.utils.helpers.ImageBindNceHeader
      model_dim: ${models.model.model_dim}
      dropout: 0.
  mask_cross_time_trf_nce:
    temp: 1.0
    proj_head:
      _target_: src.models.utils.helpers.ImageBindNceHeader
      model_dim: ${models.model.model_dim}
      dropout: 0.
  mask_latent_prediction:
    momentum: False
    loss: mse
    predictor:
      _target_: src.models.utils.header.MLPHead
      in_dim: ${models.model.model_dim}
      out_dim: ${models.model.model_dim}
      dropout: 0.
      norm: layer

  fom_args:
    reorder_prob: 0.2
    predictor:
      _target_: src.models.utils.header.MLPHead
      in_dim: ${models.model.model_dim}
      out_dim: ${models.model.num_stack}
      dropout: 0.
      norm: layer
  #---------------------------------------------------------------------------------------------------------#
  vision_args:
    short_window_len: 1
    preprocess_vision_args:
      _target_: src.models.encoders.identity.get_identity_encoder
    tokenization_vision:
      _target_: src.models.vit_implementations.VitVATT3D
      channel_size: 3
      model_dim: ${models.model.model_dim}
      num_heads: 12
      num_layers: 8
      patch_size:
        - 1
        - 16
        - 16
      input_size: # first dim = short_window_len
        - 1
        - 240
        - 160
      num_emb: 151
    pe_vision:
      _target_: src.models.encoders.identity.get_identity_encoder
    encoder_vision_args:
      _target_: src.models.encoders.identity.get_identity_encoder
  #---------------------------------------------------------------------------------------------------------#

  fusion_args:
    _target_: src.models.utils.fusion.EarlySum
    mod_names: ${models.model.mod_names}
    dim: ${models.model.model_dim}


  pos_emb_args:
    _target_: src.models.utils.positional_encoding.StandardPositionalEncoding
    d_model: ${models.model.model_dim}


  cross_time_trf_args:
    _target_: src.models.transformer_implementations.TransformerEncoderVanilla
    token_dim: ${models.model.model_dim}
    num_heads: 12
    num_blocks: 4



inference:
  ckpt_path: ' '

